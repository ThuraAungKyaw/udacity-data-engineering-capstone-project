{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# US Immigrant Data Analytics and Analysis\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "The US National Tourism and Trade Office wants a data solution to store and analyze the historical immigration data they receive daily for further use by them and related organizations. \n",
    "\n",
    "They keep record of millions of data every month and want to perform effective and efficient analysis and find insights with their data. The data that they have recorded is very raw and uncleaned so, it contains unnecessary fields, values and data with mismatched types.  Since they also want to share the data with other groups of people who aren’t dealing with it day-to-day, they want the end data to have descriptive and easy to understand column, entity names and values. In addition to the immigration data, there will be numerous data from different sources in different formats which will be used together with it to provide meaningful and valuable insights.\n",
    "\n",
    "Due to the unpredictability of the size of the data, they want the solution to work best no matter the size of the data. They also want to store the data in a place with reliable security where it is highly accessible anywhere in the country no matter what time it is.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, isnan, when, count, desc\n",
    "from pyspark.sql.functions import to_date\n",
    "import  pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, \\\n",
    "FloatType, LongType, DoubleType\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = config['AWS_CREDENTIALS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config['AWS_CREDENTIALS']['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "S3_INPUT_BUCKET = \"s3a://udacity-capstone-thura/\"\n",
    "S3_OUTPUT_BUCKET = \"s3a://udacity-capstone-thura-output/\"\n",
    "US_CITIES_DEMOGRAPHICS = \"us-cities-demographics.csv\"\n",
    "MISSING_US_DEMOGRAPHICS = \"missing-us-demographics.csv\"\n",
    "IMMIGRATION_DATA = \"sas_data\"\n",
    "AIRPORT_CODES = \"airport-codes.json\"\n",
    "LABELS_PATH = \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "KEY_LABELS = [\"i94cntyl\", \"i94prtl\", \"i94model\", \"i94addrl\"]\n",
    "\n",
    "\n",
    "substring_udf = udf(lambda x:x[3:],StringType())\n",
    "convert_date = udf(lambda x: (dt.datetime(1960, 1, 1).date() + dt.timedelta(float(x))).isoformat() if x else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "With the use of Amazon S3 and Pyspark, the project will create a cloud-based centralized data lake that users from different backgrounds will use and perform analyses on. There are 3 main data sets that are going to be used, namely:\n",
    "<ul>\n",
    "<li>US I94 Immigration Data</li>\n",
    "<li>U.S. City Demographic Data</li>\n",
    "<li>Airport Code Table</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "First, the raw data files will be hosted on Amazon S3. Pyspark will be used to read those data which have different formats <code>.csv</code>, <code>.parquet</code>, <code>.json</code>, etc. and load them into separate dataframes. In addition to that, the pre-defined label and description data will be read and loaded locally into spark dataframes. The reason the labels aren't hosted on S3 is that they rarely change and it is best to keep them separate from the main datasets.\n",
    "\n",
    "Next, the data will be explored a bit to ensure correct data had been imported and just to make sure the main columns are included in general. After that, the loaded dataframes will be cleaned by performing type casts, only extracting columns that are needed, renaming columns, filtering, dropping duplicates, etc. by leveraging the built-in functions Python and Pyspark provide. The cleaned data will then be extracted to several dataframes as per the data model that is defined. Finally, each dataframe which are now in the final stage will be written to Amazon S3 as parquet files.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "There are 3 main datasets that will be used:\n",
    "<li><b>US I94 Immigration Data</b> -  This data comes from the US National Tourism and Trade Office. As the name suggests, it includes US immigration data from a particular time period. Data which is crucial for immigration such as cicid, port of entry, immigration mode, admission number, arrival and departure date, etc. are included in this dataset.</li> \n",
    "<li><b>U.S. City Demographic Data</b> -  This data comes from OpenSoft. It includes demographics of all US cities. The data include population, city name, state, state codes, etc. The data will not be used as is. It will first be grouped and aggregated based on state and state code and then the resulting data will be used. Upon preliminary inspection of the data, there are three missing states so, the missing data is collected and stored in a separate file. The missing data references data from The U.S. Census Bureau, the same source as the original data.  </li>\n",
    "<li><b>Airport Code Table</b> - This dataset comes from DataHub. It contains airport codes from all around the world. For this use case, the airport data from US which are not closed will be used. Airport name, local code, type, country, region, coordinates, etc. are some example of the data that is included. </li> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def mapper(contents, key):\n",
    "    \"\"\"\n",
    "        Description: Accepts file contents as an object and extract information from it\n",
    "                     based on the key passed\n",
    "        Parameters:\n",
    "                     contents - file contents as an object\n",
    "                     key - key used to extract data from the file object\n",
    "        Returns: Extracted data as a dictionary\n",
    "    \"\"\"\n",
    "    temp = contents[contents.index(key):]\n",
    "    temp = temp[:temp.index(';')].split('\\n')\n",
    "    temp = [i.replace(\"'\", \"\") for i in temp]\n",
    "    data_dict = [i.split('=') for i in temp[1:]]\n",
    "    data_dict = dict([i[0].strip(), i[1].strip()] for i in data_dict if len(i) == 2)\n",
    "    return data_dict\n",
    "\n",
    "# Open the labels and descriptions file and load \n",
    "with open(LABELS_PATH) as file:\n",
    "    contents = file.read()\n",
    "    contents = contents.replace('\\t', '')\n",
    "    \n",
    "# Create/Get spark session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- category_name: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- mode_id: integer (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read labels and descriptions data\n",
    "visa_categories = {'1':'Business', '2': 'Pleasure', '3' : 'Student'}\n",
    "countries = mapper(contents, KEY_LABELS[0])\n",
    "ports = mapper(contents, KEY_LABELS[1])\n",
    "immigration_modes = mapper(contents, KEY_LABELS[2])\n",
    "i94_addresses = mapper(contents, KEY_LABELS[3])\n",
    "\n",
    "# Create Spark Dataframes for Labels and Descriptions data\n",
    "\n",
    "# Load Visa Categories Data\n",
    "visa_categories_pddf = pd.DataFrame(list(visa_categories.items()), columns=['category_id', 'category_name'])\n",
    "visa_category_df = spark.createDataFrame(visa_categories_pddf) \\\n",
    "                    .withColumn(\"category_id\",col(\"category_id\").cast(IntegerType()))\n",
    "visa_category_df.printSchema()\n",
    "\n",
    "# Load Countries Data\n",
    "countries_pddf = pd.DataFrame(list(countries.items()), columns=['country_code', 'country_name'])\n",
    "countries_df = spark.createDataFrame(countries_pddf)\\\n",
    "                            .withColumn(\"country_code\",col(\"country_code\").cast(IntegerType()))\n",
    "countries_df.printSchema()\n",
    "\n",
    "# Load Immigration Modes Data\n",
    "modes_pddf = pd.DataFrame(list(immigration_modes.items()), columns=['mode_id', 'description'])\n",
    "modes_df = spark.createDataFrame(modes_pddf)\\\n",
    "                            .withColumn(\"mode_id\",col(\"mode_id\").cast(IntegerType()))\n",
    "modes_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------+--------+---------+-----+-----------+----------+----------+------------+--------------------+-------------+\n",
      "|continent|         coordinates|elevation_ft|gps_code|iata_code|ident|iso_country|iso_region|local_code|municipality|                name|         type|\n",
      "+---------+--------------------+------------+--------+---------+-----+-----------+----------+----------+------------+--------------------+-------------+\n",
      "|       NA|-74.9336013793945...|          11|     00A|     null|  00A|         US|     US-PA|       00A|    Bensalem|   Total Rf Heliport|     heliport|\n",
      "|       NA|-101.473911, 38.7...|        3435|    00AA|     null| 00AA|         US|     US-KS|      00AA|       Leoti|Aero B Ranch Airport|small_airport|\n",
      "|       NA|-151.695999146, 5...|         450|    00AK|     null| 00AK|         US|     US-AK|      00AK|Anchor Point|        Lowell Field|small_airport|\n",
      "+---------+--------------------+------------+--------+---------+-----+-----------+----------+----------+------------+--------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- continent: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- ident: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read Airport Data\n",
    "airports_df = spark.read.json(S3_INPUT_BUCKET + AIRPORT_CODES)\n",
    "\n",
    "# See a sample data and the schema\n",
    "airports_df.show(3)\n",
    "airports_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------+---------------+-----------------+----------------+--------------+------------+\n",
      "|         city|        state|state_code|male_population|female_population|total_population|no_of_veterans|foreign_born|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+--------------+------------+\n",
      "|Silver Spring|     Maryland|        MD|          40601|            41862|           82463|          1562|       30908|\n",
      "|       Quincy|Massachusetts|        MA|          44129|            49500|           93629|          4147|       32935|\n",
      "|       Hoover|      Alabama|        AL|          38040|            46799|           84839|          4819|        8229|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+--------------+------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- male_population: long (nullable = true)\n",
      " |-- female_population: long (nullable = true)\n",
      " |-- total_population: long (nullable = true)\n",
      " |-- no_of_veterans: long (nullable = true)\n",
      " |-- foreign_born: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read Cities Data\n",
    "cities_df = spark.read.csv(S3_INPUT_BUCKET + US_CITIES_DEMOGRAPHICS, sep=\";\", header=True)\n",
    "missing_df = spark.read.csv(S3_INPUT_BUCKET + MISSING_US_DEMOGRAPHICS, header=True)\n",
    "\n",
    "# Select data with column renames and type casts\n",
    "\n",
    "cities_df = cities_df.selectExpr(\n",
    "    'City city',\n",
    "    'State state',\n",
    "    '`State Code` state_code',\n",
    "    'cast(`Male Population` as long) male_population',\n",
    "    'cast(`Female Population` as long) female_population',\n",
    "    'cast(`Total Population` as long) total_population',\n",
    "    'cast(`Number of Veterans` as long) no_of_veterans',\n",
    "    'cast(`Foreign-born` as long) foreign_born'\n",
    ")\n",
    "\n",
    "missing_df = missing_df.selectExpr(\n",
    "    'state',\n",
    "    'state_code',\n",
    "    'cast(`male_population` as long)',\n",
    "    'cast(`female_population` as long)',\n",
    "    'cast(`total_population` as long)',\n",
    "    'cast(`no_of_veterans` as long)',\n",
    "    'cast(`foreign_born` as long)'\n",
    ")\n",
    "\n",
    "# See a sample data and schema\n",
    "cities_df.show(3)\n",
    "cities_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+------+------+-------+-------+-------+-------+-------+--------------+-------+-----+--------+---------+-----+------------+--------------+-----------+----------+----------+--------+------+-------+-------+--------------+---------+---------+\n",
      "|    cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|respondent_age|i94visa|count|dtadfile|visa_post|occup|arrival_flag|departure_flag|update_flag|match_flag|birth_year| dtaddto|gender|ins_num|airline|       adm_num|flight_no|visa_type|\n",
      "+---------+-----+------+------+------+-------+-------+-------+-------+-------+--------------+-------+-----+--------+---------+-----+------------+--------------+-----------+----------+----------+--------+------+-------+-------+--------------+---------+---------+\n",
      "|5748517.0| 2016|     4|   245|   438|    LOS|20574.0|      1|     CA|20582.0|            40|      1|  1.0|20160430|      SYD| null|           G|             O|       null|         M|      1976|10292016|     F|   null|     QF|9.495387003E10|    00011|       B1|\n",
      "|5748518.0| 2016|     4|   245|   438|    LOS|20574.0|      1|     NV|20591.0|            32|      1|  1.0|20160430|      SYD| null|           G|             O|       null|         M|      1984|10292016|     F|   null|     VA|9.495562283E10|    00007|       B1|\n",
      "|5748519.0| 2016|     4|   245|   438|    LOS|20574.0|      1|     WA|20582.0|            29|      1|  1.0|20160430|      SYD| null|           G|             O|       null|         M|      1987|10292016|     M|   null|     DL|9.495640653E10|    00040|       B1|\n",
      "+---------+-----+------+------+------+-------+-------+-------+-------+-------+--------------+-------+-----+--------+---------+-----+------------+--------------+-----------+----------+----------+--------+------+-------+-------+--------------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- respondent_age: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visa_post: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- arrival_flag: string (nullable = true)\n",
      " |-- departure_flag: string (nullable = true)\n",
      " |-- update_flag: string (nullable = true)\n",
      " |-- match_flag: string (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- ins_num: long (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- adm_num: double (nullable = true)\n",
      " |-- flight_no: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load immigration data\n",
    "immigration_df = spark.read.parquet(S3_INPUT_BUCKET + IMMIGRATION_DATA)\n",
    "\n",
    "# Modify the loaded data to have appropriate names and data types\n",
    "immigration_df = immigration_df.selectExpr(\n",
    "    'cicid',\n",
    "    'cast(i94yr as int) i94yr',\n",
    "    'cast(i94mon as int) i94mon',\n",
    "    'cast(i94cit as int) i94cit',\n",
    "    'cast(i94res as int) i94res',\n",
    "    'i94port',\n",
    "    'arrdate',\n",
    "    'cast(i94mode as int) i94mode',\n",
    "    'i94addr',\n",
    "    'depdate',\n",
    "    'cast(i94bir as int) respondent_age',\n",
    "    'cast(i94visa as int) i94visa',\n",
    "    'count',\n",
    "    'dtadfile',\n",
    "    'visapost visa_post',\n",
    "    'occup',\n",
    "    'entdepa arrival_flag',\n",
    "    'entdepd departure_flag',\n",
    "    'entdepu update_flag',\n",
    "    'matflag match_flag',\n",
    "    'cast(biryear as int) birth_year',\n",
    "    'dtaddto',\n",
    "    'gender',\n",
    "    'cast(insnum as long) ins_num',\n",
    "    'airline',\n",
    "    'admnum adm_num',\n",
    "    'fltno flight_no',\n",
    "    'visatype visa_type')\n",
    "\n",
    "\n",
    "# See sample data\n",
    "immigration_df.show(3)\n",
    "immigration_df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Through exploring the data I have found the followings for each dataset:\n",
    "\n",
    "##### Immigration Data\n",
    "\n",
    "<ul>\n",
    "<li>There are pver 3 million records in this dataset.</li>\n",
    "<li>There aren’t any rows where the cicid is null or duplicated.</li>   \n",
    "<li>The main i94 data fields don’t have any null values.</li>   \n",
    "<li>Most of the rows don’t have occupation, INS number and update_flag data. Approximately 96.3 percent of the rows don't have INS number, 99 percent of the rows don't have occupation and 99.8 percent of the rows don't have update_flag.</li>\n",
    "<li>Birth year is between 1902 and 2019 across the entire dataset. No adnormal data is seen here.</li>\n",
    "<li>Looking through the gender column, it can be estimated that males immigrated more than females. It should be noted that there are over four hundred thousand rows where gender is null. Since we are more concerned about the main i94 fields, this isn't much of a concern but this should be taken into consideration of all analyses where gender info is included.</li>\n",
    "<li>The original date format for both arrival and departure dates are sas date format and they are converted to yyyy-MM-dd format for further processing and analysis.</li>\n",
    "<li>Arrival date is between 2016–04-01 and 2016–04-30 which implies the data is reflective of the immigration period that occurred in April 2016.</li>\n",
    "<li>Even though the data revolves around the timeframe of April 2016, there are 3 departure dates which are either too far off in the past or the future. Minimum and maximum departure date is between 2001-07-20 and 2084-05-16. This is 3 rows out of 3 million so it wouldn't affect the accuracy of the data much.\n",
    "</li>\n",
    "<li>dtadfile and dtaddto columns have varying date formats so they will also be converted to yyyy-MM-dd format for consistence.</li>\n",
    "<li>In the mode of transport, on top of the cases where it is not reported (which falls in to the category id of 9), there is a count of 239 null fields. Air is the most used mode of immigration. </li>\n",
    "<li>There are some rows where airline (airline) and flight number (fltno) are null and it is acceptable because there are immigrations where the mode of transport is not by air.</li>\n",
    "<li>Most people migrated using the WT visa type.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "##### Airport Code Data\n",
    "\n",
    "<li>Since we are only interested in the airports that are in the US, all the airport information that are outside the US is filtered out.</li>\n",
    "<li>In addition to that, the airports which are closed and those where there is no local_code will also be filtered out.</li>\n",
    "<li>The iso_country column will be dropped cause we are only going to be looking that the US airports.</li>\n",
    "<li>The iso_region column will also be dropped after the region codes are stripped and made into another column.</li>\n",
    "<li>The columns gps_code and iata_code has a lot of missing values so they will be dropped.</li>\n",
    "<li>The elevation feet is within an acceptable range.</li>\n",
    "<li>The type of airport that has the most count is “small”.</li>\n",
    "<li>Texas (TX) state has the most airports with the count being 2017.</li>\n",
    "\n",
    "\n",
    "##### US Cities Demographics Data\n",
    "<li>For this data solution, instead of cities, states data are needed so they will first be aggregated and grouped by state name and code.</li>\n",
    "<li>There isn't data for 3 US states: Vermont, West Virginia and Wyoming so the missing data are collected from the same data source as the main dataset and kept in a separate file to be processed together later.</li>\n",
    "<li>Female population is higher than male population.</li>\n",
    "<li>The state of California has the most population with Texas being the second.</li>\n",
    "<li>Before aggregation, there is one row where both number of veterans and foreign-born columns are null.</li>\n",
    "<li>The “Race” and “Count” columns are not used cause they don’t provide information that is relevant to this particular use.</li>\n",
    "\n",
    "#### Cleaning Steps\n",
    "Steps necessary to clean the data differ a bit on an individual dataset.\n",
    "##### Cleaning Immigration Data\n",
    "<li>Since there are a bunch of data with different types, it is not favourable to let spark to infer data schema. </li>\n",
    "<li>First, after loading the data, <code>selectExpr</code> function will be used to extract the data with desired data types. Along with that, some columns will be given descriptive names to make them easily comprehensible.</li>\n",
    "<li>sas dates will be type casted to a more readable date format.</li>\n",
    "<li>Duplicates will be dropped if there is any.</li>\n",
    "<li>Unnecessary columns will be droppped.</li>\n",
    "\n",
    "##### Cleaning Airport Code Data\n",
    "<li>After loading the data, airports which are not in the US will be filtered out along with the ones that are closed.</li>\n",
    "<li>Rows where the local_code is empty will also be filtered out.</li>\n",
    "<li>iso_region column will be stripped to get region code for each row and the original column will later be dropped.</li>\n",
    "<li>Appropriate type castings will take place. For instance, the elevation_ft column will be casted to integer type.</li>\n",
    "<li>Some columns will be renamed to be more readable.</li>\n",
    "<li>Duplicates will be dropped if there is any.</li>\n",
    "<li>Unnecessary columns will be droppped.</li>\n",
    "\n",
    "\n",
    "##### Cleaning US Cities Demographics Data\n",
    "<li>After loading the data, <code>selectExpr</code> function will be used to extract the data with desired data types. Along with that, some columns will be given descriptive names to make them easily comprehensible.</li>\n",
    "<li>Since there are missing values as stated above, they will be loaded from a separate file and be added to the main dataframe later on after it has been cleaned. </li>\n",
    "<li>States data is needed instead of the individual cites so, the loaded dataframe will be grouped by state name and code.</li>\n",
    "<li>After the main dataframe had been shaped, the missing data that had been loaded will be appended to it.</li>\n",
    "<li>Duplicates will be dropped if there is any.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- respondent_age: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visa_post: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- arrival_flag: string (nullable = true)\n",
      " |-- departure_flag: string (nullable = true)\n",
      " |-- update_flag: string (nullable = true)\n",
      " |-- match_flag: string (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- ins_num: long (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- adm_num: double (nullable = true)\n",
      " |-- flight_no: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- date_adm_to: date (nullable = true)\n",
      " |-- date_added: date (nullable = true)\n",
      "\n",
      "root\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- male_population: long (nullable = true)\n",
      " |-- female_population: long (nullable = true)\n",
      " |-- total_population: long (nullable = true)\n",
      " |-- no_of_veterans: long (nullable = true)\n",
      " |-- foreign_born: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- continent: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Type castings, data modifying, column renaming, etc.\n",
    "\n",
    "# Immigration Data\n",
    "immigration_df = immigration_df.withColumn('arrival_date', convert_date(immigration_df.arrdate).cast('date'))\n",
    "immigration_df = immigration_df.withColumn('departure_date', convert_date(immigration_df.depdate).cast('date'))\n",
    "immigration_df = immigration_df.withColumn('date_adm_to', F.to_date(F.unix_timestamp(immigration_df.dtaddto, 'MMddyyyy').cast('timestamp')))\n",
    "immigration_df = immigration_df.withColumn('date_added', F.to_date(F.unix_timestamp(immigration_df.dtadfile, 'yyyyMMdd').cast('timestamp')))\n",
    "immigration_df.printSchema()\n",
    "\n",
    "# Cities Data\n",
    "# What I really want is the states data so, the data need to be aggregated\n",
    "cities_df = cities_df.groupBy(\"state\", \"state_code\") \\\n",
    "            .sum(\"male_population\",\"female_population\", \"total_population\", \"no_of_veterans\", \"foreign_born\")\n",
    "\n",
    "states_df = cities_df.withColumnRenamed(\"sum(male_population)\",\"male_population\") \\\n",
    "            .withColumnRenamed(\"sum(female_population)\",\"female_population\") \\\n",
    "            .withColumnRenamed(\"sum(total_population)\",\"total_population\") \\\n",
    "            .withColumnRenamed(\"sum(no_of_veterans)\",\"no_of_veterans\") \\\n",
    "            .withColumnRenamed(\"sum(foreign_born)\",\"foreign_born\") \\\n",
    "\n",
    "# Add missing data to the dataframe\n",
    "states_df = states_df.unionByName(missing_df)\n",
    "\n",
    "states_df.printSchema()\n",
    "\n",
    "# Airport Data\n",
    "# Filtering Airport Data to have airports that are in the US and are not closed\n",
    "airports_df = airports_df.filter((airports_df.iso_country  == \"US\") \\\n",
    "                      & (airports_df.type  != \"closed\") \\\n",
    "                      & (col('local_code').isNotNull()))\n",
    "                     \n",
    "\n",
    "# Modifying airport data\n",
    "airports_df = airports_df.withColumn('region', substring_udf('iso_region'))\n",
    "airports_df = airports_df.withColumnRenamed(\"ident\",\"id\")\n",
    "airports_df = airports_df.withColumn(\"elevation_ft\", col(\"elevation_ft\").cast('integer'))\n",
    "\n",
    "airports_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|gender|  count|\n",
      "+------+-------+\n",
      "|     F|1302743|\n",
      "|  null| 414269|\n",
      "|     M|1377224|\n",
      "|     U|    467|\n",
      "|     X|   1610|\n",
      "+------+-------+\n",
      "\n",
      "+---------+-------+\n",
      "|visa_type|  count|\n",
      "+---------+-------+\n",
      "|       F2|   2984|\n",
      "|      GMB|    150|\n",
      "|       B2|1117897|\n",
      "|       F1|  39016|\n",
      "|      CPL|     10|\n",
      "|       I1|    234|\n",
      "|       WB| 282983|\n",
      "|       M1|   1317|\n",
      "|       B1| 212410|\n",
      "|       WT|1309059|\n",
      "|       M2|     49|\n",
      "|       CP|  14758|\n",
      "|      GMT|  89133|\n",
      "|       E1|   3743|\n",
      "|        I|   3176|\n",
      "|       E2|  19383|\n",
      "|      SBP|     11|\n",
      "+---------+-------+\n",
      "\n",
      "+-----+-----+\n",
      "|occup|count|\n",
      "+-----+-----+\n",
      "|  PHA|    5|\n",
      "|  REL|    3|\n",
      "|  ENT|    3|\n",
      "|  ACH|   29|\n",
      "|  101|    1|\n",
      "|  EMM|    4|\n",
      "|  ULS|  175|\n",
      "|  GEN|    3|\n",
      "|  MTH|    1|\n",
      "|  DVM|    2|\n",
      "|  SVC|    3|\n",
      "|  ECH|   11|\n",
      "|  EXA|  196|\n",
      "|  ENV|    1|\n",
      "|  ENP|    2|\n",
      "|  PRF|   11|\n",
      "|  VOC|   10|\n",
      "|  TCH|   26|\n",
      "|  MSC|    3|\n",
      "|  AST|    2|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+---------------+\n",
      "|min(birth_year)|max(birth_year)|\n",
      "+---------------+---------------+\n",
      "|           1902|           2019|\n",
      "+---------------+---------------+\n",
      "\n",
      "+-------------------+-------------------+\n",
      "|min(departure_date)|max(departure_date)|\n",
      "+-------------------+-------------------+\n",
      "|         2001-07-20|         2084-05-16|\n",
      "+-------------------+-------------------+\n",
      "\n",
      "+-----------------+-----------------+\n",
      "|min(arrival_date)|max(arrival_date)|\n",
      "+-----------------+-----------------+\n",
      "|       2016-04-01|       2016-04-30|\n",
      "+-----------------+-----------------+\n",
      "\n",
      "+-----+\n",
      "|cicid|\n",
      "+-----+\n",
      "+-----+\n",
      "\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+--------------+-------+-----+--------+---------+-------+------------+--------------+-----------+----------+----------+-------+------+-------+-------+-------+---------+---------+------------+--------------+-----------+----------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|respondent_age|i94visa|count|dtadfile|visa_post|  occup|arrival_flag|departure_flag|update_flag|match_flag|birth_year|dtaddto|gender|ins_num|airline|adm_num|flight_no|visa_type|arrival_date|departure_date|date_adm_to|date_added|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+--------------+-------+-----+--------+---------+-------+------------+--------------+-----------+----------+----------+-------+------+-------+-------+-------+---------+---------+------------+--------------+-----------+----------+\n",
      "|    0|    0|     0|     0|     0|      0|      0|    239| 152592| 142457|           802|      0|    0|       1|  1881250|3088187|         238|        138429|    3095921|    138429|       802|    477|414269|2983010|  83627|      0|    19549|        0|           0|        142457|      45824|         1|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+--------------+-------+-----+--------+---------+-------+------------+--------------+-----------+----------+----------+-------+------+-------+-------+-------+---------+---------+------------+--------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring Immigration Data\n",
    "\n",
    "# Get entry count based on gender\n",
    "gender_count = immigration_df.groupby(['gender']).count()\n",
    "gender_count.show()\n",
    "\n",
    "# Get entry count based on visatype\n",
    "visa_count = immigration_df.groupby(['visa_type']).count()\n",
    "visa_count.show()\n",
    "\n",
    "# Get entry count based on occupation \n",
    "occup_count = immigration_df.groupby(['occup']).count()\n",
    "occup_count.show()\n",
    "\n",
    "# Get minimum and maximum birth year \n",
    "immigration_df.agg(F.min(col('birth_year')), F.max(col('birth_year'))).show()\n",
    "\n",
    "# Get minimum and maximum departure date\n",
    "immigration_df.agg(F.min(col('departure_date')), F.max(col('departure_date'))).show()\n",
    "\n",
    "# Get minimum and maximum arrival date\n",
    "immigration_df.agg(F.min(col('arrival_date')), F.max(col('arrival_date'))).show()\n",
    "\n",
    "# Check if there are rows with duplicated cicid\n",
    "immigration_df.groupBy(\"cicid\").count().where(\"count > 1\").drop(\"count\").show()\n",
    "\n",
    "# Null value count across columns\n",
    "immigration_df.select([count(when(col(c).isNull(), c)).alias(c) for c in immigration_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|region|count|\n",
      "+------+-----+\n",
      "|    TX| 2017|\n",
      "|    CA|  985|\n",
      "|    FL|  884|\n",
      "|    PA|  851|\n",
      "|    IL|  813|\n",
      "|    AK|  782|\n",
      "|    OH|  713|\n",
      "|    IN|  631|\n",
      "|    NY|  581|\n",
      "|    WI|  572|\n",
      "|    WA|  554|\n",
      "|    MO|  545|\n",
      "|    LA|  533|\n",
      "|    MN|  509|\n",
      "|    MI|  495|\n",
      "|    GA|  488|\n",
      "|    CO|  475|\n",
      "|    VA|  472|\n",
      "|    OR|  469|\n",
      "|    OK|  468|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------+-----+\n",
      "|          type|count|\n",
      "+--------------+-----+\n",
      "| large_airport|  170|\n",
      "|   balloonport|   17|\n",
      "| seaplane_base|  562|\n",
      "|      heliport| 6161|\n",
      "|medium_airport|  685|\n",
      "| small_airport|13364|\n",
      "+--------------+-----+\n",
      "\n",
      "+-----------------+-----------------+\n",
      "|min(elevation_ft)|max(elevation_ft)|\n",
      "+-----------------+-----------------+\n",
      "|             -210|            29977|\n",
      "+-----------------+-----------------+\n",
      "\n",
      "+---------+-----------+------------+--------+---------+---+-----------+----------+----------+------------+----+----+------+\n",
      "|continent|coordinates|elevation_ft|gps_code|iata_code| id|iso_country|iso_region|local_code|municipality|name|type|region|\n",
      "+---------+-----------+------------+--------+---------+---+-----------+----------+----------+------------+----+----+------+\n",
      "|        0|          0|         151|     349|    18996|  0|          0|         0|         0|          13|   0|   0|     0|\n",
      "+---------+-----------+------------+--------+---------+---+-----------+----------+----------+------------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring Airport Data\n",
    "\n",
    "# Get entry count based on state\n",
    "count_by_state = airports_df.groupby(['region']).count()\n",
    "count_by_state.sort(col(\"count\").desc()).show()\n",
    "\n",
    "# Get entry count based on airport type\n",
    "count_by_airport_type = airports_df.groupby(['type']).count()\n",
    "count_by_airport_type.show()\n",
    "\n",
    "# Get minimum and maximum elevation feet \n",
    "airports_df.agg(F.min(col('elevation_ft')), F.max(col('elevation_ft'))).show()\n",
    "\n",
    "# Null value count across columns\n",
    "airports_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in airports_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|     state|male_population|\n",
      "+----------+---------------+\n",
      "|California|       61055672|\n",
      "|     Texas|       34862194|\n",
      "|  New York|       23422799|\n",
      "|   Florida|       15461937|\n",
      "|   Arizona|       11137275|\n",
      "+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+-----------------+\n",
      "|     state|female_population|\n",
      "+----------+-----------------+\n",
      "|California|         62388681|\n",
      "|     Texas|         35691659|\n",
      "|  New York|         25579256|\n",
      "|   Florida|         16626425|\n",
      "|  Illinois|         11570526|\n",
      "+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+----------------+\n",
      "|     state|total_population|\n",
      "+----------+----------------+\n",
      "|California|       123444353|\n",
      "|     Texas|        70553853|\n",
      "|  New York|        49002055|\n",
      "|   Florida|        32306132|\n",
      "|  Illinois|        22514390|\n",
      "+----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+------------+\n",
      "|     state|foreign_born|\n",
      "+----------+------------+\n",
      "|California|    37059662|\n",
      "|  New York|    17186873|\n",
      "|     Texas|    14498054|\n",
      "|   Florida|     7845566|\n",
      "|  Illinois|     4632600|\n",
      "+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+--------------+\n",
      "|     state|no_of_veterans|\n",
      "+----------+--------------+\n",
      "|California|       4617022|\n",
      "|     Texas|       3429512|\n",
      "|   Florida|       1861951|\n",
      "|   Arizona|       1322525|\n",
      "|  Virginia|       1148830|\n",
      "+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+----------------------+\n",
      "|sum(male_population)|sum(female_population)|\n",
      "+--------------------+----------------------+\n",
      "|           282583682|             295425151|\n",
      "+--------------------+----------------------+\n",
      "\n",
      "+-----+----------+---------------+-----------------+----------------+--------------+------------+\n",
      "|state|state_code|male_population|female_population|total_population|no_of_veterans|foreign_born|\n",
      "+-----+----------+---------------+-----------------+----------------+--------------+------------+\n",
      "|    0|         0|              0|                0|               0|             1|           1|\n",
      "+-----+----------+---------------+-----------------+----------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring Cities Data\n",
    "states_df.select(\"state\", \"male_population\").sort(col(\"male_population\").desc()).show(5)\n",
    "\n",
    "states_df.select(\"state\", \"female_population\").sort(col(\"female_population\").desc()).show(5)\n",
    "\n",
    "states_df.select(\"state\", \"total_population\").sort(col(\"total_population\").desc()).show(5)\n",
    "\n",
    "states_df.select(\"state\", \"foreign_born\").sort(col(\"foreign_born\").desc()).show(5)\n",
    "\n",
    "states_df.select(\"state\", \"no_of_veterans\").sort(col(\"no_of_veterans\").desc()).show(5)\n",
    "\n",
    "# Get total sum of male and female population \n",
    "states_df.agg(F.sum(col('male_population')), F.sum(col('female_population'))).show()\n",
    "\n",
    "# Null value count across columns\n",
    "states_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in states_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- respondent_age: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- visa_post: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- arrival_flag: string (nullable = true)\n",
      " |-- departure_flag: string (nullable = true)\n",
      " |-- update_flag: string (nullable = true)\n",
      " |-- match_flag: string (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- ins_num: long (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- adm_num: double (nullable = true)\n",
      " |-- flight_no: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- date_adm_to: date (nullable = true)\n",
      " |-- date_added: date (nullable = true)\n",
      "\n",
      "Immigration data row count: 3096313\n",
      "root\n",
      " |-- continent: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n",
      "\n",
      " Airport data row count: 20959\n",
      "root\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- male_population: long (nullable = true)\n",
      " |-- female_population: long (nullable = true)\n",
      " |-- total_population: long (nullable = true)\n",
      " |-- no_of_veterans: long (nullable = true)\n",
      " |-- foreign_born: long (nullable = true)\n",
      "\n",
      "States data row count: 52\n",
      "root\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- category_name: string (nullable = true)\n",
      "\n",
      "Visa category data row count: 3\n",
      "root\n",
      " |-- mode_id: integer (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n",
      "\n",
      " Immigration mode data row count: 4\n",
      "root\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      "\n",
      "Countries data row count: 289\n"
     ]
    }
   ],
   "source": [
    "# Dropping the duplicates in the three dataframes if there is any\n",
    "immigration_df = immigration_df.dropDuplicates()\n",
    "airports_df = airports_df.dropDuplicates()\n",
    "states_df = states_df.dropDuplicates()\n",
    "countries_df = countries_df.dropDuplicates()\n",
    "\n",
    "# Dropping the unnecessary columns\n",
    "immigration_df = immigration_df.drop(\"count\", \"arrdate\", \"depdate\", \"dtaddto\", \"dtadfile\")\n",
    "airports_df = airports_df.drop('iso_country', 'iso_region', 'gps_code', 'iata_code')\n",
    "\n",
    "\n",
    "immigration_df.printSchema()\n",
    "print(f\"Immigration data row count: {immigration_df.count()}\")\n",
    "\n",
    "airports_df.printSchema()\n",
    "print(f\"\\n Airport data row count: {airports_df.count()}\")\n",
    "\n",
    "states_df.printSchema()\n",
    "print(f\"States data row count: {states_df.count()}\")\n",
    "\n",
    "visa_category_df.printSchema()\n",
    "print(f\"Visa category data row count: {visa_category_df.count()}\")\n",
    "\n",
    "modes_df.printSchema()\n",
    "print(f\"\\n Immigration mode data row count: {modes_df.count()}\")\n",
    "\n",
    "countries_df.printSchema()\n",
    "print(f\"Countries data row count: {countries_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "![ETL](images/data_model.png \"ETL 3\") \n",
    "\n",
    "As shown in the above picture, the conceptual data model is structured using the star schema methodology with the Immigration being the centralized fact table with a few dimension tables surrounding it. The main immigration data is separated into two tables Immigration and Respondent_info just to make the fact table look cleaner and concise. The other dimension tables enriches and extends the fact table with more information. \n",
    "\n",
    "The star schema methodology is adopted here because of several beneficial reasons. Since the data needs to be shared with other organizations where there is going to be people from different backgrounds, it is important that the model is easy to understand. With star schema, everything revolves around the fact table and everything is connected through it which makes it easy to comprehend since the table relations aren't all over the place.\n",
    "\n",
    "Beacuse of the fact that the data are divided into different smaller tables, users can be query specific parts of data where unnecessary data won't be brought up which gives fast performance. In addition to that, there is no need to do numerous complex joins which makes querying faster compared to other models where it is necessary to do four or five joins across tables to get the resulting data. For instance, if one wants to get insights about the top countries where the immigrants come from, only Countries and Immigration tables need to be joined to get the desired insight. The star schema methodology has been around for quite some time now so, many business intelligence tools support it.\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "Since the data has been shaped and cleaned in the above stages, there isn't much left to do to get it into the chosen data model.\n",
    "<li>New dataframes will be created from the cleaned data with appropriate names to fit the specified model.</li>\n",
    "<li>Row counts will be stored in a dictionary to do data qualtiy checks later.</li>\n",
    "<li>Each table will be written as separate parquet files to a designated Amazon S3 bucket.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visa_category_table row count: 3\n",
      "immigration_mode_table row count: 4\n",
      "countries_table row count: 289\n",
      "states_table row count: 52\n",
      "airports_table row count: 20959\n",
      "respondent_info_table row count: 3096313\n",
      "fact_immigration_table row count: 3096313\n"
     ]
    }
   ],
   "source": [
    "source_row_counts = {}\n",
    "\n",
    "# Define Visa Category Table\n",
    "visa_category_table = visa_category_df.select(col(\"category_id\").alias(\"id\"), \n",
    "                                              col(\"category_name\").alias(\"name\"))\n",
    "\n",
    "source_row_counts['visa_categories'] = visa_category_table.count()\n",
    "\n",
    "print(f\"visa_category_table row count: {source_row_counts['visa_categories']}\")\n",
    "\n",
    "\n",
    "# Define Immigration Mode Table\n",
    "immigration_mode_table = modes_df.select(col(\"mode_id\").alias(\"id\"), \n",
    "                                         col(\"description\"))\n",
    "\n",
    "source_row_counts['immigration_modes'] = immigration_mode_table.count()\n",
    "\n",
    "print(f\"immigration_mode_table row count: {source_row_counts['immigration_modes']}\")\n",
    "\n",
    "\n",
    "# Define Countries Table\n",
    "countries_table = countries_df.select(col(\"country_code\").alias(\"code\"), \n",
    "                                      col(\"country_name\").alias(\"name\"))\n",
    "\n",
    "source_row_counts['countries'] = countries_table.count()\n",
    "\n",
    "print(f\"countries_table row count: {source_row_counts['countries']}\")\n",
    "\n",
    "# Define States Table\n",
    "states_table = states_df.select(col(\"state\").alias(\"name\"), \n",
    "                                col(\"state_code\").alias(\"code\"), \n",
    "                                col(\"male_population\"), \n",
    "                                col(\"female_population\"), \n",
    "                                col(\"total_population\"), \n",
    "                                col(\"no_of_veterans\"), \n",
    "                                col(\"foreign_born\"))\n",
    "\n",
    "source_row_counts['states'] = states_table.count()\n",
    "\n",
    "print(f\"states_table row count: {source_row_counts['states']}\")\n",
    " \n",
    "# Define Airports Table\n",
    "airports_table = airports_df.select(col(\"id\"), \n",
    "                                    col(\"local_code\"),\n",
    "                                    col(\"name\"), \n",
    "                                    col(\"type\"), \n",
    "                                    col(\"region\"), \n",
    "                                    col(\"continent\"), \n",
    "                                    col(\"elevation_ft\"), \n",
    "                                    col(\"coordinates\"), \n",
    "                                    col(\"municipality\"))\n",
    "\n",
    "source_row_counts['airports'] = airports_table.count()\n",
    "\n",
    "print(f\"airports_table row count: {source_row_counts['airports']}\")\n",
    " \n",
    "\n",
    "# Define Respondent Info Table\n",
    "respondent_info_table = immigration_df.select(col(\"cicid\"), \n",
    "                                              col(\"adm_num\"), \n",
    "                                              col(\"ins_num\"),\n",
    "                                              col(\"respondent_age\").alias(\"age\"), \n",
    "                                              col(\"gender\"), \n",
    "                                              col(\"occup\"), \n",
    "                                              col(\"birth_year\"), \n",
    "                                              col(\"arrival_date\"), \n",
    "                                              col(\"departure_date\"), \n",
    "                                              col(\"visa_post\"),\n",
    "                                              col(\"visa_type\"),\n",
    "                                              col(\"arrival_flag\"),\n",
    "                                              col(\"departure_flag\"), \n",
    "                                              col(\"update_flag\"), \n",
    "                                              col(\"match_flag\"), \n",
    "                                              col(\"date_adm_to\")) \n",
    "\n",
    "\n",
    "source_row_counts['respondent_info'] = respondent_info_table.count()\n",
    "\n",
    "print(f\"respondent_info_table row count: {source_row_counts['respondent_info']}\")\n",
    "\n",
    "# Define Immigration Table\n",
    "fact_immigration_table = immigration_df.select(col(\"cicid\"), \n",
    "                                              col(\"i94yr\"), \n",
    "                                              col(\"i94mon\"),\n",
    "                                              col(\"i94cit\"), \n",
    "                                              col(\"i94res\"), \n",
    "                                              col(\"i94port\"), \n",
    "                                              col(\"i94mode\"), \n",
    "                                              col(\"i94addr\"), \n",
    "                                              col(\"i94visa\"),\n",
    "                                              col(\"airline\"),\n",
    "                                              col(\"flight_no\"),\n",
    "                                              col(\"date_added\")) \n",
    "\n",
    "source_row_counts['immigration'] = fact_immigration_table.count()\n",
    "\n",
    "print(f\"fact_immigration_table row count: {source_row_counts['immigration']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- code: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- male_population: long (nullable = true)\n",
      " |-- female_population: long (nullable = true)\n",
      " |-- total_population: long (nullable = true)\n",
      " |-- no_of_veterans: long (nullable = true)\n",
      " |-- foreign_born: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- adm_num: double (nullable = true)\n",
      " |-- ins_num: long (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- visa_post: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- arrival_flag: string (nullable = true)\n",
      " |-- departure_flag: string (nullable = true)\n",
      " |-- update_flag: string (nullable = true)\n",
      " |-- match_flag: string (nullable = true)\n",
      " |-- date_adm_to: date (nullable = true)\n",
      "\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight_no: string (nullable = true)\n",
      " |-- date_added: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing schemas to see if the tables have correct column names and types before writing to S3\n",
    "visa_category_table.printSchema()\n",
    "immigration_mode_table.printSchema()\n",
    "countries_table.printSchema()\n",
    "states_table.printSchema()\n",
    "airports_table.printSchema()\n",
    "respondent_info_table.printSchema()\n",
    "fact_immigration_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visa_categories dimension table has been written to the S3 bucket.\n",
      "immigration_modes dimension table has been written to the S3 bucket.\n",
      "countries dimension table has been written to the S3 bucket.\n",
      "states dimension table has been written to the S3 bucket.\n",
      "airports dimension table has been written to the S3 bucket.\n",
      "respondent_info dimension table has been written to the S3 bucket.\n",
      "immigration fact table has been written to the S3 bucket.\n"
     ]
    }
   ],
   "source": [
    "# Write tables to S3 as parquet files\n",
    "\n",
    "visa_category_table.write.mode(\"overwrite\") \\\n",
    "                    .parquet(os.path.join(S3_OUTPUT_BUCKET, 'visa_categories'))\n",
    "print(\"visa_categories dimension table has been written to the S3 bucket.\")\n",
    "\n",
    "immigration_mode_table.write.mode(\"overwrite\") \\\n",
    "                    .parquet(os.path.join(S3_OUTPUT_BUCKET, 'immigration_modes'))\n",
    "print(\"immigration_modes dimension table has been written to the S3 bucket.\")\n",
    "\n",
    "countries_table.coalesce(15).write.mode(\"overwrite\") \\\n",
    "                    .parquet(os.path.join(S3_OUTPUT_BUCKET, 'countries'))\n",
    "print(\"countries dimension table has been written to the S3 bucket.\")\n",
    "\n",
    "states_table.coalesce(15).write.mode(\"overwrite\") \\\n",
    "                    .parquet(os.path.join(S3_OUTPUT_BUCKET, 'states'))\n",
    "print(\"states dimension table has been written to the S3 bucket.\")\n",
    "\n",
    "airports_table.coalesce(15).write.mode(\"overwrite\") \\\n",
    "                    .parquet(os.path.join(S3_OUTPUT_BUCKET, 'airports'))\n",
    "print(\"airports dimension table has been written to the S3 bucket.\")\n",
    "\n",
    "respondent_info_table.coalesce(18).write.mode(\"overwrite\") \\\n",
    "                    .parquet(os.path.join(S3_OUTPUT_BUCKET, 'respondent_info'))\n",
    "print(\"respondent_info dimension table has been written to the S3 bucket.\")\n",
    "\n",
    "fact_immigration_table.coalesce(18).write.mode(\"overwrite\") \\\n",
    "                    .parquet(os.path.join(S3_OUTPUT_BUCKET, 'immigration'))\n",
    "print(\"immigration fact table has been written to the S3 bucket.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet files have been read.\n"
     ]
    }
   ],
   "source": [
    "# Read the parquet files that were written\n",
    "dim_visa_categories = spark.read.parquet(S3_OUTPUT_BUCKET + \"visa_categories/\")\n",
    "\n",
    "dim_immigration_modes = spark.read.parquet(S3_OUTPUT_BUCKET + \"immigration_modes/\")\n",
    "\n",
    "dim_countries = spark.read.parquet(S3_OUTPUT_BUCKET + \"countries/\")\n",
    "\n",
    "dim_states = spark.read.parquet(S3_OUTPUT_BUCKET + \"states/\")\n",
    "\n",
    "dim_airports = spark.read.parquet(S3_OUTPUT_BUCKET + \"airports/\")\n",
    "\n",
    "dim_respondent_info = spark.read.parquet(S3_OUTPUT_BUCKET + \"respondent_info/\")\n",
    "\n",
    "fact_immigration = spark.read.parquet(S3_OUTPUT_BUCKET + \"immigration/\")\n",
    "\n",
    "print(\"Parquet files have been read.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "\n",
    "There are a few data quality checks that are going to be performed here to ensure the pipeline ran as expected. These include:\n",
    "\n",
    "<li>Check if each table has rows</li>\n",
    "<li>Check if each table has the same row count as the source</li>\n",
    "<li>Check there aren't null or duplicated unique keys</li>\n",
    "<li>Run sample queries</li>\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_visa_categories table has 3 rows.         \n",
      "\tHas rows: True         \n",
      "\tRow count same as the source: True\n",
      "\n",
      "dim_immigration_modes table has 4 rows.         \n",
      "\tHas rows: True         \n",
      "\tRow count same as the source: True\n",
      "\n",
      "dim_countries table has 289 rows.         \n",
      "\tHas rows: True         \n",
      "\tRow count same as the source: True\n",
      "\n",
      "dim_states table has 52 rows.         \n",
      "\tHas rows: True         \n",
      "\tRow count same as the source: True\n",
      "\n",
      "dim_airports table has 20959 rows.         \n",
      "\tHas rows: True         \n",
      "\tRow count same as the source: True\n",
      "\n",
      "dim_respondent_info table has 3096313 rows.         \n",
      "\tHas rows: True         \n",
      "\tRow count same as the source: True\n",
      "\n",
      "fact_immigration table has 3096313 rows.         \n",
      "\tHas rows: True         \n",
      "\tRow count same as the source: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Checks\n",
    "\n",
    "# Check if they have rows and if they have the same count as the source \n",
    "dim_visa_categories_count = dim_visa_categories.count()\n",
    "print(f\"dim_visa_categories table has {dim_visa_categories_count} rows. \\\n",
    "        \\n\\tHas rows: {dim_visa_categories_count > 0} \\\n",
    "        \\n\\tRow count same as the source: {source_row_counts['visa_categories'] == dim_visa_categories_count}\\n\")\n",
    "\n",
    "dim_immigration_modes_count = dim_immigration_modes.count()\n",
    "print(f\"dim_immigration_modes table has {dim_immigration_modes_count} rows. \\\n",
    "        \\n\\tHas rows: {dim_immigration_modes_count > 0} \\\n",
    "        \\n\\tRow count same as the source: {source_row_counts['immigration_modes'] == dim_immigration_modes_count}\\n\")\n",
    "\n",
    "dim_countries_count = dim_countries.count() \n",
    "print(f\"dim_countries table has {dim_countries_count} rows. \\\n",
    "        \\n\\tHas rows: {dim_countries_count > 0} \\\n",
    "        \\n\\tRow count same as the source: {source_row_counts['countries'] == dim_countries_count}\\n\")\n",
    "\n",
    "dim_states_count = dim_states.count()\n",
    "print(f\"dim_states table has {dim_states_count} rows. \\\n",
    "        \\n\\tHas rows: {dim_states_count > 0} \\\n",
    "        \\n\\tRow count same as the source: {source_row_counts['states'] == dim_states_count}\\n\")\n",
    "\n",
    "dim_airports_count = dim_airports.count()\n",
    "print(f\"dim_airports table has {dim_airports_count} rows. \\\n",
    "        \\n\\tHas rows: {dim_airports_count > 0} \\\n",
    "        \\n\\tRow count same as the source: {source_row_counts['airports'] == dim_airports_count}\\n\")\n",
    "\n",
    "dim_respondent_info_count = dim_respondent_info.count()\n",
    "print(f\"dim_respondent_info table has {dim_respondent_info_count} rows. \\\n",
    "        \\n\\tHas rows: {dim_respondent_info_count > 0} \\\n",
    "        \\n\\tRow count same as the source: {source_row_counts['respondent_info'] == dim_respondent_info_count}\\n\")\n",
    "\n",
    "fact_immigration_count = fact_immigration.count()\n",
    "print(f\"fact_immigration table has {fact_immigration_count} rows. \\\n",
    "        \\n\\tHas rows: {fact_immigration_count > 0} \\\n",
    "        \\n\\tRow count same as the source: {source_row_counts['immigration'] == fact_immigration_count}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visa category id duplicate count: 0\n",
      "immigration mode id duplicate count: 0\n",
      "country code duplicate count: 0\n",
      "state code duplicate count: 0\n",
      "airport id duplicate count: 0\n",
      "respondent cicid duplicate count: 0\n",
      "immigration cicid duplicate count: 0\n"
     ]
    }
   ],
   "source": [
    "vsac_id_dups = dim_visa_categories.groupBy(\"id\").count().where(\"count > 1\")\n",
    "print(f\"visa category id duplicate count: {vsac_id_dups.count()}\")\n",
    "\n",
    "imode_id_dups = dim_immigration_modes.groupBy(\"id\").count().where(\"count > 1\")\n",
    "print(f\"immigration mode id duplicate count: {imode_id_dups.count()}\")\n",
    "\n",
    "cnty_code_dups = dim_countries.groupBy(\"code\").count().where(\"count > 1\")\n",
    "print(f\"country code duplicate count: {cnty_code_dups.count()}\")\n",
    "\n",
    "sts_code_dups = dim_states.groupBy(\"code\").count().where(\"count > 1\")\n",
    "print(f\"state code duplicate count: {sts_code_dups.count()}\")\n",
    "\n",
    "ap_id_dups = dim_airports.groupBy(\"id\").count().where(\"count > 1\")\n",
    "print(f\"airport id duplicate count: {ap_id_dups.count()}\")\n",
    "\n",
    "res_cicid_dups = dim_respondent_info.groupBy(\"cicid\").count().where(\"count > 1\")\n",
    "print(f\"respondent cicid duplicate count: {res_cicid_dups.count()}\")\n",
    "\n",
    "fact_cicid_dups = fact_immigration.groupBy(\"cicid\").count().where(\"count > 1\")\n",
    "print(f\"immigration cicid duplicate count: {fact_cicid_dups.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visa category id null count: 0\n",
      "immigration mode id null count: 0\n",
      "country code null count: 0\n",
      "state code null count: 0\n",
      "airport id null count: 0\n",
      "respondent cicid null count: 0\n",
      "immigration cicid null count: 0\n"
     ]
    }
   ],
   "source": [
    "# Check null values on primary key columns\n",
    "\n",
    "vsac_id_nulls = dim_visa_categories.select([count(when(col(c).isNull(), c)).alias(c) for c in ['id']])\n",
    "print(f\"visa category id null count: {vsac_id_nulls.first().id}\")\n",
    "\n",
    "imode_id_nulls = dim_immigration_modes.select([count(when(col(c).isNull(), c)).alias(c) for c in ['id']])\n",
    "print(f\"immigration mode id null count: {imode_id_nulls.first().id}\")\n",
    "\n",
    "cnty_code_nulls = dim_countries.select([count(when(col(c).isNull(), c)).alias(c) for c in ['code']])\n",
    "print(f\"country code null count: {cnty_code_nulls.first().code}\")\n",
    "\n",
    "sts_code_nulls = dim_states.select([count(when(col(c).isNull(), c)).alias(c) for c in ['code']])\n",
    "print(f\"state code null count: {sts_code_nulls.first().code}\")\n",
    "\n",
    "ap_id_nulls = dim_airports.select([count(when(col(c).isNull(), c)).alias(c) for c in ['id']])\n",
    "print(f\"airport id null count: {ap_id_nulls.first().id}\")\n",
    "\n",
    "res_cicid_nulls = dim_respondent_info.select([count(when(col(c).isNull(), c)).alias(c) for c in ['cicid']])\n",
    "print(f\"respondent cicid null count: {res_cicid_nulls.first().cicid}\")\n",
    "\n",
    "fact_cicid_nulls = fact_immigration.select([count(when(col(c).isNull(), c)).alias(c) for c in ['cicid']])\n",
    "print(f\"immigration cicid null count: {fact_cicid_nulls.first().cicid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                name|count(1)|\n",
      "+--------------------+--------+\n",
      "|      UNITED KINGDOM|  368421|\n",
      "|               JAPAN|  249167|\n",
      "|          CHINA, PRC|  185609|\n",
      "|              FRANCE|  185339|\n",
      "|MEXICO Air Sea, a...|  179603|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  487163|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample Queries\n",
    "fact_immigration.createOrReplaceTempView('immigration')\n",
    "dim_countries.createOrReplaceTempView('countries')\n",
    "dim_respondent_info.createOrReplaceTempView('respondent_info')\n",
    "\n",
    "# Top countries from which immigrants visit the US\n",
    "top_countries = spark.sql(\"\"\"\n",
    "        SELECT co.name,\n",
    "               count(*)\n",
    "        FROM immigration im\n",
    "        JOIN countries co\n",
    "        ON co.code = im.i94res\n",
    "        GROUP BY 1\n",
    "        ORDER BY 2 DESC\n",
    "\"\"\")\n",
    "\n",
    "top_countries.show(5)\n",
    "\n",
    "# Count of immigrants whose age is over 60\n",
    "over_60 = spark.sql(\"\"\"\n",
    "        SELECT count(*)\n",
    "        FROM immigration im\n",
    "        JOIN respondent_info ri\n",
    "        ON ri.cicid = im.cicid\n",
    "        WHERE ri.age > 60\n",
    "\"\"\")\n",
    "\n",
    "over_60.show()\n",
    "\n",
    "# Immigration and Respondent Info Join\n",
    "respondent_immigration = spark.sql(\"\"\"\n",
    "        SELECT im.cicid,\n",
    "               im.i94yr,\n",
    "               im.i94mon,\n",
    "               im.i94cit,\n",
    "               im.i94res,\n",
    "               im.i94visa,\n",
    "               im.i94addr,\n",
    "               im.airline,\n",
    "               im.flight_no,\n",
    "               ri.adm_num,\n",
    "               ri.age,\n",
    "               ri.gender,\n",
    "               ri.birth_year,\n",
    "               ri.arrival_date,\n",
    "               ri.departure_date\n",
    "        FROM immigration im\n",
    "        JOIN respondent_info ri\n",
    "        ON ri.cicid = im.cicid\n",
    "\"\"\")\n",
    "respondent_immigration.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "##### Immigration Table\n",
    "\n",
    "\n",
    "<li><code>cicid</code> - Unique identifier for the immigrants</li>\n",
    "<li><code>i94yr</code> - 4 digit year</li>\n",
    "<li><code>i94mon</code> - Numeric month</li>\n",
    "<li><code>i94cit</code> - 3 digit code of the country of citizenship</li>\n",
    "<li><code>i94res</code> - 3 digit code of the country of residence</li>\n",
    "<li><code>i94port</code> - 3 character code of the destination city. The port of entry to the US</li>\n",
    "<li><code>i94mode</code> - Mode of immigration</li>\n",
    "<li><code>i94addr</code> - The final address of the migrants, where they currently live in the US</li>\n",
    "<li><code>i94visa</code> - Reason for immigration</li>\n",
    "<li><code>airline</code> - Airline used to arrive in the US</li>\n",
    "<li><code>flight_no</code> - Flight number of the airline used to arrive in the US</li>\n",
    "<li><code>date_added</code> - Date added to I-94 files.</li>\n",
    "\n",
    "\n",
    "##### Respondent_Info Table\n",
    "\n",
    "<li><code>cicid</code> - Unique identifier for the immigrants</li>\n",
    "<li><code>adm_num</code> - Admission number</li>\n",
    "<li><code>ins_num</code> - INS number</li>\n",
    "<li><code>age</code> -  Age of the respondent</li>\n",
    "<li><code>gender</code> - Non-immigrant sex</li>\n",
    "<li><code>occup</code> - Occupation that will be performed in the US</li>\n",
    "<li><code>birth_year</code> - 4 digit year of birth</li>\n",
    "<li><code>arrival_date</code> - The arrival date in the US</li>\n",
    "<li><code>departure_date</code> - The departure date from the US</li>\n",
    "<li><code>visa_post</code> - The department of state where the visa was issued</li>\n",
    "<li><code>visa_type</code> - Class of admission</li>\n",
    "<li><code>arrival_flag</code> - Status flag indicating if the migrant has been admitted or paroled into the US</li>\n",
    "<li><code>departure_flag</code> - Status flag indicating if the migrant has departed, lost I-94 or is deceased</li>\n",
    "<li><code>update_flag</code> - Status flag indicating if the migrant has been apprehended, overstayed, adjusted to perm residence</li>\n",
    "<li><code>match_flag</code> - Match of arrival and departure records</li>\n",
    "<li><code>date_adm_to</code> - Date to which allowed to stay until in the US</li>\n",
    "\n",
    "##### Airports Table\n",
    "\n",
    "<li><code>id</code> - Unique identifier for the airport</li>\n",
    "<li><code>local_code</code> - The local country code for the airport</li>\n",
    "<li><code>name</code> - The official name of the airport</li>\n",
    "<li><code>type</code> -  Type of the airport</li>\n",
    "<li><code>region</code> - The region that the airport belongs to</li>\n",
    "<li><code>continent</code> - The continent that the airport belongs to</li>\n",
    "<li><code>elevation_ft</code> - The airport elevation in feet</li>\n",
    "<li><code>coordinates</code> - The coordinates for the airport</li>\n",
    "<li><code>municipality</code> - The primary municipality that the airport serves</li>\n",
    "\n",
    "##### States Table\n",
    "\n",
    "<li><code>name</code> - The name of the state</li>\n",
    "<li><code>code</code> - 2 character code of a US state</li>\n",
    "<li><code>male_population</code> - Male population count of the state</li>\n",
    "<li><code>female_population</code> - Female population count of the state</li>\n",
    "<li><code>total_population</code> - Total population count of the state</li>\n",
    "<li><code>no_of_veterans</code> - Number of veterans in the state</li>\n",
    "<li><code>foreign_born</code> - Number of foreign born people in the state</li>\n",
    "\n",
    "##### Countries Table\n",
    "\n",
    "<li><code>code</code> - 3 digit country code</li>\n",
    "<li><code>name</code> - The name of the country</li>\n",
    "\n",
    "##### ImmigrationModes Table\n",
    "\n",
    "<li><code>id</code> - Immigration mode id</li>\n",
    "<li><code>description</code> - A brief name or description of the immigration mode</li>\n",
    "\n",
    "##### VisaCategories Table\n",
    "\n",
    "<li><code>id</code> - Visa category id</li>\n",
    "<li><code>name</code> - The name of the category</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people.\n",
    " \n",
    "#### Tools and Technologies Used\n",
    "\n",
    "<li><b>Amazon S3 </b> - An object storage service. Since we are dealing with sensitive data of the immigrants' personal information, we need a storage with reliable security and Amazon S3 provides exactly that. We cannot predict the size of the data since it might change rapidly according to the time of the year or the other travel situations. Not only it is inexpensive, it is highly scalable which is beneficial for the type of data we are dealing with. As stated in the project summary, the data will be shared across the different organizations and storing here helps cause of its 99.9% availability and its user friendly interface.\n",
    "</li>\n",
    "<li><b>Spark (Pyspark)</b> - An open-source unified analytics engine for large-scale data processing. Here we are using an interface of it in Python. Since we are dealing with millions of data, it is crucial to be able to process them efficiently. Spark is an advanced analytical tool which can process large volumes data much faster than other tools like Hadoop. It has many built-in functions for data analyzing so, it doesn't matter if one doesn't know SQL or one isn't that familiar with Python. </li>\n",
    "<li><b>Pandas </b> - An easy to use open source data analysis and manipulation tool built with python. It has the ability to turn python dictionaries and arrays into dataframes and is mainly used here for that.\n",
    "\n",
    "#### Schedule Proposal\n",
    " \n",
    "<span>Since I-94 database is updated monthly, I propose that there should be a monthly schedule where the data gets updated at each month’s end. Other major datasets like Airports and Demographics data gets updated less often than the immigration data so this should be enough.</span>\n",
    "\n",
    "#### Scenarios to consider\n",
    "\n",
    "##### The data was increased by 100x.\n",
    "    \n",
    "* In this case, for processing, I would make good use of spark's parallism and increase worker nodes to work with. For data storage, I would write the data to Amazon Redshift since it is more flexible than S3.\n",
    "\n",
    "##### The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    \n",
    "* I would use Apache's Airflow and place a scheduler that would trigger the update task at 7am every day.\n",
    "\n",
    "##### The database needed to be accessed by 100+ people.\n",
    "* According to Amazon, S3 can handle 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket which should be enough but as the users increase, it would be more structured approach would be to use Amazon Redshift as a storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
